{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSYC 193: Perception and Computation \n",
    "## Lab 3: Higher-level feature representations and kNN classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we will continue working with an image dataset used in a recent computer vision paper by [Sangkloy et al.](https://dl.acm.org/doi/abs/10.1145/2897824.2925954). \n",
    "\n",
    "**Learning objectives**\n",
    "* Higher-level feature representations of images\n",
    "* Representational Dissimilarity Matrices\n",
    "\n",
    "**Submission instructions**\n",
    "1. Please rename the notebook by replacing `YOURUSERNAME` in the filename with your actual UCSD AD username. \n",
    "2. Before submitting your assignment, sure that your notebook can run from \"top to bottom,\" executing the code in every code cell without returning fatal errors. An easy way to verify this is to click \"Kernel\" above in the tool bar, and try selecting \"Restart & Run All.\"\n",
    "3. Once you have verified that your notebook can run \"top to bottom\" without issues, click \"File\" in the toolbar above, then \"Download as,\" then \"PDF via LaTeX\" to download a PDF version of your notebook. \n",
    "4. Upload this PDF version of your notebook to Canvas before 5pm the next class period. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load generally useful python modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output\n",
    "\n",
    "## load pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### general params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'images'\n",
    "feature_dir = 'features'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import image metadata (from Sangkloy et al. (2016))\n",
    "from photodraw32_metadata import metadata\n",
    "M = pd.DataFrame(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load and display a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = M['s3_url'].values[0] \n",
    "print('Example Image URL: {}'.format(url))\n",
    "response = requests.get(url)\n",
    "img1 = Image.open(BytesIO(response.content))\n",
    "img1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_im(url, out_dir = 'images'):\n",
    "    '''\n",
    "    input:\n",
    "        url: str, image URL for single image\n",
    "        out_dir: str, path to location where you want to save this image\n",
    "    output:\n",
    "        image saved to file\n",
    "    '''\n",
    "    ## extract filename from URL\n",
    "    fname = url.split('/')[-1]\n",
    "    \n",
    "    if not os.path.exists(os.path.join(out_dir,fname)):\n",
    "\n",
    "        ## get image data\n",
    "        response = requests.get(url)    \n",
    "        img = Image.open(BytesIO(response.content))\n",
    "\n",
    "        ## create data_dir if it does not already exist\n",
    "        ### INSERT YOUR CODE HERE ###\n",
    "\n",
    "        ## save image here\n",
    "        img.save(os.path.join(### INSERT YOUR CODE HERE ###))\n",
    "        print('Saved image {} to {}'.format(fname, out_dir))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print('Already have image {} saved, passing over.'.format(fname))\n",
    "        \n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download images, passing over those we've already downloaded\n",
    "for ind, url in enumerate(M['s3_url'].values): \n",
    "    x = download_im(url, out_dir = 'images')\n",
    "    clear_output(wait=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract image features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PIXELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rescale to this imsize\n",
    "imsize = 64\n",
    "\n",
    "## get list of paths \n",
    "im_paths = [os.path.join(data_dir, path) for path in M.s3_filename.values]\n",
    "\n",
    "## init P pixel feature matrix\n",
    "PF = np.zeros((M.shape[0], ### INSERT YOUR CODE HERE ###))\n",
    "num_pix_feats = PF.shape[1]\n",
    "\n",
    "## create new column that corresponds to image_id column in VGG metadata\n",
    "M['image_id'] = M.apply(lambda x: x['s3_filename'].split('.')[0], axis=1)\n",
    "\n",
    "## iterate over image paths and add pixel feature representation to P feature matrix\n",
    "for ind, path in enumerate(im_paths):\n",
    "    im = ### INSERT YOUR CODE HERE ###\n",
    "    vec = ### INSERT YOUR CODE HERE ###\n",
    "    PF[ind,:] = vec\n",
    "    print('Extracting pixel feature representation for {}'.format(path))\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "## join pixel feature matrix and metadata to form single PIXEL dataframe\n",
    "P = ### INSERT YOUR CODE HERE ###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG19 \"fc6\" features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pre-extracted, only extract if you wish to overwrite\n",
    "extract=False\n",
    "if extract:\n",
    "    cmd_string = \"python extract_features.py --data={} --out_dir={}\".format(data_dir,feature_dir)\n",
    "    os.system(cmd_string)\n",
    "    \n",
    "## load in feature matrix and apply preprocessing (channel-wise normalization)\n",
    "from extract_features import normalize\n",
    "VF = normalize(np.load('features/FEATURES_FC6_IMAGES.npy'))\n",
    "num_vgg_feats = VF.shape[1]\n",
    "\n",
    "## load in metadata corresponding to VGG features\n",
    "VM = pd.read_csv('features/METADATA_images.csv')    \n",
    "\n",
    "## join feature matrix and metadata to form single VGG dataframe\n",
    "V = VM.join(pd.DataFrame(VF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create new columns to make it easier to sort into categories alphabetically\n",
    "V['category'] = V.apply(lambda x: x['image_id'].split('_')[-2], axis=1)\n",
    "V.loc[V['category']=='(sedan)', 'category'] = 'car_(sedan)' ## deal with exception, so categories sort properly\n",
    "\n",
    "V['img_ind'] = VM.apply(lambda x: x['image_id'].split('_')[-1], axis=1)\n",
    "\n",
    "## sort rows by category, then by img_ind\n",
    "V.sort_values(by=['category','img_ind'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualize dissimilarity between images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize correlation matrix for VGG-19 representation of images\n",
    "corrmat = ### INSERT YOUR CODE HERE ###\n",
    "plt.figure(figsize=(12,12))\n",
    "sns.heatmap(corrmat, square=True, xticklabels='', yticklabels='', cbar_kws={'shrink':0.8})\n",
    "t = plt.title('image correlation matrix for VGG features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visualize correlation matrix for pixel representation of images\n",
    "plt.figure(figsize=(12,12))\n",
    "corrmat = np.corrcoef(### INSERT YOUR CODE HERE ###)\n",
    "sns.heatmap(corrmat, square=True, xticklabels='', yticklabels='', cbar_kws={'shrink':0.8})\n",
    "t = plt.title('image correlation matrix for pixel representation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What differences do you notice between the two RDMs above?\n",
    "\n",
    "_Insert your response here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category RDMs\n",
    "Based on the 1024x1024 image-level RDM for the VGG features, derive a 32x32 category-level RDM, where each cell represents the correlation between mean feature vector for category1 and the mean feature vector for category2.\n",
    "\n",
    "BONUS: Apply clustering over these mean feature vectors to find a way of ordering them that highlights similarities between categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize using t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE is a popular and useful visualization tool for examining structure in high-dimensional data. To learn more about t-SNE, check out this article from [Distill.pub](https://distill.pub/2016/misread-tsne/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualizing clusters of images using VGG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "_VF = PCA(n_components=50).fit_transform(VF)\n",
    "__VF = TSNE(n_components=2).fit_transform(_VF)\n",
    "VF_ = pd.DataFrame(__VF)\n",
    "VF_.columns=['tsne_0', 'tsne_1']\n",
    "V = V.join(VF_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(data=V, \n",
    "                x='tsne_0',\n",
    "                y='tsne_1',\n",
    "                hue='category',\n",
    "                legend=False)\n",
    "plt.title('t-SNE visualization of image clusters using VGG features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualizing clusters of images using pixel features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "_PF = ### INSERT YOUR CODE HERE ###\n",
    "PF_ = ### INSERT YOUR CODE HERE ###\n",
    "PF_.columns=['tsne_0', 'tsne_1']\n",
    "P = P.join(PF_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(data=P, \n",
    "                x='tsne_0',\n",
    "                y='tsne_1',\n",
    "                hue='category',\n",
    "                legend=False)\n",
    "plt.title('t-SNE visualization of image clusters using pixel features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What differences do you notice between the two scatterplots above?\n",
    "\n",
    "_Insert your response here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
